version: '3.8'

services:
  lerobot-training:
    build:
      context: .
      dockerfile: Dockerfile
      args:
        REPO_URL: https://github.com/catebros/lerobot 
    image: lerobot-training:latest

    # GPU
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

    volumes:
      # Mount local HuggingFace cache -> with my dataset -> CHANGE THIS !!!!
      # Mount outputs directory
      # Mount your training config into the container
      - /home/cbarbero/.cache/huggingface:/workspace/hf_cache
      - ./outputs:/workspace/outputs
      - ./train_diffusion_config.yaml:/workspace/lerobot/train_diffusion_config.yaml

    # Set environment variables
    environment:
      - CUDA_VISIBLE_DEVICES=0
      - PYTHONUNBUFFERED=1
      - HF_HOME=/workspace/hf_cache
      - HUGGINGFACE_HUB_CACHE=/workspace/hf_cache
      - HF_TOKEN=${HF_TOKEN}  

    # Keep container running
    stdin_open: truew w
    tty: true
    command: bash
